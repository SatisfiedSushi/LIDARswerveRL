{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMEFOLDER set to: /root/MultiAgent/FTCTraining/\n",
      "Models Directory: /root/MultiAgent/FTCTraining/models\n",
      "Research Directory: /root/MultiAgent/FTCTraining/models/research\n",
      "Final Output Folder: /root/MultiAgent/FTCTraining/final_output\n",
      "Training Progress Directory: /root/MultiAgent/FTCTraining/training_progress\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Define the home folder for your project\n",
    "HOMEFOLDER = '/root/MultiAgent/FTCTraining/'  # Update this path if different\n",
    "\n",
    "# Set environment variable\n",
    "os.environ[\"HOMEFOLDER\"] = HOMEFOLDER\n",
    "\n",
    "# Define other important directories\n",
    "MODELS_DIR = os.path.join(HOMEFOLDER, 'models')\n",
    "RESEARCH_DIR = os.path.join(MODELS_DIR, 'research')\n",
    "SCRIPTS_DIR = os.path.join(MODELS_DIR, 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
    "FINALOUTPUTFOLDER = os.path.join(HOMEFOLDER, FINALOUTPUTFOLDER_DIRNAME)\n",
    "TRAINING_PROGRESS_DIR = os.path.join(HOMEFOLDER, 'training_progress')\n",
    "\n",
    "# Print paths for verification\n",
    "print(f\"HOMEFOLDER set to: {HOMEFOLDER}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Research Directory: {RESEARCH_DIR}\")\n",
    "print(f\"Final Output Folder: {FINALOUTPUTFOLDER}\")\n",
    "print(f\"Training Progress Directory: {TRAINING_PROGRESS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing directory: /root/MultiAgent/FTCTraining/models\n",
      "Removed existing directory: /root/MultiAgent/FTCTraining/training_progress\n",
      "Created directory: /root/MultiAgent/FTCTraining/training_progress\n",
      "Removed existing directory: /root/MultiAgent/FTCTraining/final_output\n",
      "Created directory: /root/MultiAgent/FTCTraining/final_output\n"
     ]
    }
   ],
   "source": [
    "# Remove existing 'models' directory if it exists to avoid Git clone errors\n",
    "if os.path.exists(MODELS_DIR):\n",
    "    shutil.rmtree(MODELS_DIR)\n",
    "    print(f\"Removed existing directory: {MODELS_DIR}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {MODELS_DIR}\")\n",
    "\n",
    "# Remove and recreate 'training_progress' and 'final_output' directories\n",
    "for directory in [TRAINING_PROGRESS_DIR, FINALOUTPUTFOLDER]:\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "        print(f\"Removed existing directory: {directory}\")\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Created directory: {directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf_slim) (1.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pillow in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (11.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: lvis in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (0.5.3)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (0.12.1)\n",
      "Requirement already satisfied: Cython>=0.29.12 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (3.0.11)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (1.4.8)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (4.11.0.86)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib>=3.1.1->lvis) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib>=3.1.1->lvis) (4.55.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib>=3.1.1->lvis) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib>=3.1.1->lvis) (11.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: Cython in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (3.0.11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: contextlib2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (21.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Hit:4 http://security.ubuntu.com/ubuntu noble-security InRelease               \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease               \n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64  InRelease\n",
      "Fetched 126 kB in 1s (206 kB/s)\n",
      "Reading package lists... Done\n",
      "W: https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "protobuf-compiler is already the newest version (3.21.12-8.2build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 115 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install required Python packages\n",
    "!pip install tf_slim\n",
    "!pip install pillow\n",
    "!pip install lvis\n",
    "!pip install Cython\n",
    "!pip install contextlib2\n",
    "!pip install matplotlib\n",
    "\n",
    "# Install protocol buffers compiler if not already installed\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y protobuf-compiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/root/MultiAgent/FTCTraining/models'...\n",
      "remote: Enumerating objects: 4306, done.\u001b[K\n",
      "remote: Counting objects: 100% (4306/4306), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3325/3325), done.\u001b[K\n",
      "remote: Total 4306 (delta 1208), reused 2115 (delta 908), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (4306/4306), 53.17 MiB | 11.46 MiB/s, done.\n",
      "Resolving deltas: 100% (1208/1208), done.\n",
      "/root/MultiAgent/FTCTraining/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 3055, done.\u001b[K\n",
      "remote: Counting objects: 100% (3055/3055), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1359/1359), done.\u001b[K\n",
      "remote: Total 1824 (delta 1223), reused 701 (delta 446), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (1824/1824), 10.05 MiB | 13.47 MiB/s, done.\n",
      "Resolving deltas: 100% (1223/1223), completed with 739 local objects.\n",
      "From https://github.com/tensorflow/models\n",
      " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\n",
      "Note: switching to 'ad1f7b56943998864db8f5db0706950e93bb7d81'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at ad1f7b5 adjust folder path\n",
      "ad1f7b56943998864db8f5db0706950e93bb7d81\n"
     ]
    }
   ],
   "source": [
    "# Clone the TensorFlow Models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models {MODELS_DIR}\n",
    "\n",
    "# Navigate to the models directory\n",
    "%cd {MODELS_DIR}\n",
    "\n",
    "# Checkout the specific commit to ensure consistency\n",
    "!git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81\n",
    "!git checkout ad1f7b56943998864db8f5db0706950e93bb7d81\n",
    "\n",
    "# Verify the current commit\n",
    "!git rev-parse HEAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/MultiAgent/FTCTraining/models/research\n",
      "Protocol buffers compiled and PYTHONPATH updated.\n"
     ]
    }
   ],
   "source": [
    "# Navigate to the research directory\n",
    "%cd {RESEARCH_DIR}\n",
    "\n",
    "# Compile the protocol buffers\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# Add the research and slim directories to PYTHONPATH\n",
    "sys.path.append(os.path.join(MODELS_DIR, 'research'))\n",
    "sys.path.append(os.path.join(MODELS_DIR, 'research', 'slim'))\n",
    "\n",
    "print(\"Protocol buffers compiled and PYTHONPATH updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/MultiAgent/FTCTraining/models/research\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: avro-python3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.62.0)\n",
      "Requirement already satisfied: pillow in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (11.1.0)\n",
      "Requirement already satisfied: lxml in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (5.3.0)\n",
      "Requirement already satisfied: matplotlib in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (3.10.0)\n",
      "Requirement already satisfied: Cython in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (3.0.11)\n",
      "Requirement already satisfied: contextlib2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (21.6.0)\n",
      "Requirement already satisfied: tf-slim in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (1.17.0)\n",
      "Requirement already satisfied: pycocotools in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.0.8)\n",
      "Requirement already satisfied: lvis in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (1.15.1)\n",
      "Requirement already satisfied: pandas in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.2.3)\n",
      "Requirement already satisfied: tf-models-official>=2.5.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: tensorflow_io in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: keras in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: sacrebleu<=2.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from object_detection==0.1) (2.2.0)\n",
      "Requirement already satisfied: portalocker in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (3.1.1)\n",
      "Requirement already satisfied: regex in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
      "Requirement already satisfied: colorama in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: gin-config in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.160.0)\n",
      "Requirement already satisfied: immutabledict in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.1)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.17)\n",
      "Requirement already satisfied: oauth2client in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.11.0.86)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\n",
      "Requirement already satisfied: sentencepiece in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: seqeval in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.7)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-text~=2.15.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: tensorflow~=2.15.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from pandas->object_detection==0.1) (2025.1)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (3.10.15)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.10.0)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.65.5)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (3.4.2)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.7.1)\n",
      "Requirement already satisfied: packaging>=22.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (24.2)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.11)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.26.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.25.6)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.23.0)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from apache-beam->object_detection==0.1) (0.6)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis->object_detection==0.1) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis->object_detection==0.1) (1.4.8)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from lvis->object_detection==0.1) (4.11.0.86)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib->object_detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from matplotlib->object_detection==0.1) (4.55.8)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.24.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.1.1)\n",
      "Requirement already satisfied: docopt in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.1.31)\n",
      "Requirement already satisfied: tqdm in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.3.0)\n",
      "Requirement already satisfied: bleach in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.2.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (75.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-hub>=0.6.0->tf-models-official>=2.5.1->object_detection==0.1) (2.15.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
      "Requirement already satisfied: click in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.8)\n",
      "Requirement already satisfied: promise in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
      "Requirement already satisfied: simple-parsing in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.16.1)\n",
      "Requirement already satisfied: toml in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: etils>=1.9.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
      "Requirement already satisfied: fsspec in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2024.12.0)\n",
      "Requirement already satisfied: importlib_resources in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
      "Requirement already satisfied: zipp in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.66.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
      "Requirement already satisfied: webencodings in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from simple-parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.2)\n",
      "Building wheels for collected packages: object_detection\n",
      "  Building wheel for object_detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1655500 sha256=897d516382f5b79bb599a4925a99f24a4286a21618c3a8ad8319910b1d75ee15\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5nzzna51/wheels/b6/2f/03/c8b84fe9815921b7e43b436d3a5ec0a12f379883962017df92\n",
      "Successfully built object_detection\n",
      "Installing collected packages: object_detection\n",
      "  Attempting uninstall: object_detection\n",
      "    Found existing installation: object_detection 0.1\n",
      "    Uninstalling object_detection-0.1:\n",
      "      Successfully uninstalled object_detection-0.1\n",
      "Successfully installed object_detection-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mObject Detection API installed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install the Object Detection API\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "\n",
    "# Install the package\n",
    "!python -m pip install .\n",
    "\n",
    "print(\"Object Detection API installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:13:10.262971: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-01 11:13:10.290184: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-01 11:13:10.290238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-01 11:13:10.290931: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 11:13:10.295564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-01 11:13:10.864688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-01 11:13:12.605471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.639573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.639733: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "Running tests under Python 3.11.11: /root/miniconda/envs/FTCTrainingEnv/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2025-02-01 11:13:12.650443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.650545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.650584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.903872: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.903962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.903984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:13:12.904028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:12.904059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
      "W0201 11:13:13.064810 139692597778240 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
      "/root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0201 11:13:13.202492 139692597778240 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.81s\n",
      "I0201 11:13:13.457306 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.81s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.27s\n",
      "I0201 11:13:13.728026 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.27s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.19s\n",
      "I0201 11:13:13.918141 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.17s\n",
      "I0201 11:13:14.090254 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.17s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.38s\n",
      "I0201 11:13:15.466572 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.38s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0201 11:13:15.475728 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0201 11:13:15.493291 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0201 11:13:15.504410 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0201 11:13:15.516669 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "I0201 11:13:15.585402 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "I0201 11:13:15.644536 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n",
      "I0201 11:13:15.817844 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.17s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "I0201 11:13:15.888082 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "I0201 11:13:15.962646 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "I0201 11:13:15.988499 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0201 11:13:16.105782 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0201 11:13:16.105911 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
      "I0201 11:13:16.105965 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
      "I0201 11:13:16.107884 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:16.134382 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:16.134536 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:16.210693 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:16.210829 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:16.389742 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:16.389855 139692597778240 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0201 11:13:16.536370 139692597778240 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0201 11:13:16.536473 139692597778240 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0201 11:13:16.768116 139692597778240 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0201 11:13:16.768221 139692597778240 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0201 11:13:16.978036 139692597778240 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0201 11:13:16.978185 139692597778240 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0201 11:13:17.277916 139692597778240 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0201 11:13:17.278034 139692597778240 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0201 11:13:17.347800 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0201 11:13:17.380448 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:17.411243 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0201 11:13:17.411345 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
      "I0201 11:13:17.411373 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
      "I0201 11:13:17.412573 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:17.423873 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:17.423979 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:17.521299 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:17.521403 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:16.264475 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:16.264575 139692597778240 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0201 11:13:16.439230 139692597778240 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0201 11:13:16.439335 139692597778240 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0201 11:13:16.676860 139692597778240 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0201 11:13:16.676966 139692597778240 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0201 11:13:16.908772 139692597778240 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0201 11:13:16.908873 139692597778240 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0201 11:13:17.203162 139692597778240 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0201 11:13:17.203271 139692597778240 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0201 11:13:17.330976 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0201 11:13:17.351310 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:17.383800 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0201 11:13:17.383901 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
      "I0201 11:13:17.383941 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
      "I0201 11:13:17.384860 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:17.396980 139692597778240 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0201 11:13:17.397080 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:17.483734 139692597778240 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0201 11:13:17.483835 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:17.641092 139692597778240 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0201 11:13:17.641216 139692597778240 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0201 11:13:17.837217 139692597778240 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0201 11:13:17.837335 139692597778240 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0201 11:13:18.112907 139692597778240 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0201 11:13:18.113017 139692597778240 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0201 11:13:18.386483 139692597778240 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0201 11:13:18.386586 139692597778240 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0201 11:13:18.810512 139692597778240 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0201 11:13:18.810614 139692597778240 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0201 11:13:18.942471 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0201 11:13:18.967857 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:19.000123 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0201 11:13:19.000223 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
      "I0201 11:13:19.000250 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
      "I0201 11:13:19.001206 139692597778240 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0201 11:13:19.015042 139692597778240 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0201 11:13:19.015127 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:19.107710 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:19.107803 139692597778240 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0201 11:13:19.283167 139692597778240 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0201 11:13:19.283287 139692597778240 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0201 11:13:19.441631 139692597778240 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0201 11:13:19.441730 139692597778240 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0201 11:13:19.726159 139692597778240 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0201 11:13:19.726255 139692597778240 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0201 11:13:20.023142 139692597778240 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0201 11:13:20.023240 139692597778240 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0201 11:13:20.371996 139692597778240 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0201 11:13:20.372107 139692597778240 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0201 11:13:20.491972 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0201 11:13:20.520887 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:20.558634 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0201 11:13:20.558733 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
      "I0201 11:13:20.558777 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I0201 11:13:20.559775 139692597778240 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0201 11:13:20.573576 139692597778240 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0201 11:13:20.573662 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:20.657391 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:20.657484 139692597778240 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0201 11:13:20.860026 139692597778240 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0201 11:13:20.860144 139692597778240 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0201 11:13:21.094755 139692597778240 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0201 11:13:21.094850 139692597778240 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0201 11:13:21.441132 139692597778240 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0201 11:13:21.441233 139692597778240 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0201 11:13:21.794972 139692597778240 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0201 11:13:21.795072 139692597778240 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0201 11:13:22.259050 139692597778240 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0201 11:13:22.259140 139692597778240 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0201 11:13:22.380004 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0201 11:13:22.404472 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:22.441278 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0201 11:13:22.441384 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
      "I0201 11:13:22.441409 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
      "I0201 11:13:22.442339 139692597778240 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0201 11:13:22.453674 139692597778240 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0201 11:13:22.453769 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:22.577124 139692597778240 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0201 11:13:22.577214 139692597778240 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0201 11:13:22.853241 139692597778240 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0201 11:13:22.853337 139692597778240 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0201 11:13:23.149338 139692597778240 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0201 11:13:23.149433 139692597778240 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0201 11:13:23.717010 139692597778240 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0201 11:13:23.717102 139692597778240 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0201 11:13:24.165402 139692597778240 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0201 11:13:24.165494 139692597778240 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0201 11:13:24.705351 139692597778240 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0201 11:13:24.705448 139692597778240 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0201 11:13:24.880282 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0201 11:13:24.902297 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:24.946526 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0201 11:13:24.946631 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I0201 11:13:24.946659 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I0201 11:13:24.947651 139692597778240 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0201 11:13:24.962628 139692597778240 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0201 11:13:24.962710 139692597778240 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0201 11:13:25.112943 139692597778240 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0201 11:13:25.113047 139692597778240 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0201 11:13:25.456677 139692597778240 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0201 11:13:25.456775 139692597778240 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0201 11:13:25.841965 139692597778240 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0201 11:13:25.842061 139692597778240 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0201 11:13:26.341083 139692597778240 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0201 11:13:26.341200 139692597778240 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0201 11:13:26.830889 139692597778240 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0201 11:13:26.831008 139692597778240 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0201 11:13:27.524689 139692597778240 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0201 11:13:27.524797 139692597778240 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0201 11:13:27.713003 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0201 11:13:27.736145 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0201 11:13:27.782393 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0201 11:13:27.782495 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
      "I0201 11:13:27.782536 139692597778240 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
      "I0201 11:13:27.783677 139692597778240 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0201 11:13:27.799813 139692597778240 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0201 11:13:27.799921 139692597778240 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0201 11:13:27.981117 139692597778240 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0201 11:13:27.981228 139692597778240 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0201 11:13:28.420130 139692597778240 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0201 11:13:28.420246 139692597778240 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0201 11:13:29.063767 139692597778240 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0201 11:13:29.063881 139692597778240 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0201 11:13:29.728235 139692597778240 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0201 11:13:29.728333 139692597778240 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0201 11:13:30.401908 139692597778240 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0201 11:13:30.402008 139692597778240 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0201 11:13:31.244385 139692597778240 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0201 11:13:31.244485 139692597778240 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0201 11:13:31.496742 139692597778240 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0201 11:13:31.521401 139692597778240 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 15.59s\n",
      "I0201 11:13:31.578690 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 15.59s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
      "I0201 11:13:31.682023 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0201 11:13:31.682871 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0201 11:13:31.683133 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0201 11:13:31.683739 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0201 11:13:31.684288 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0201 11:13:31.684483 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0201 11:13:31.684864 139692597778240 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 20.483s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# Verify the installation by running the test script\n",
    "!python object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tf_slim/data/tfexample_decoder.py updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to tfexample_decoder.py\n",
    "tf_slim_path = '/root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tf_slim/data/tfexample_decoder.py'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(tf_slim_path):\n",
    "    with open(tf_slim_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        # Add TensorFlow import and replace deprecated functions\n",
    "        content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
    "        content = re.sub(r'control_flow_ops\\.case', 'tf.case', content)\n",
    "        content = re.sub(r'control_flow_ops\\.cond', 'tf.compat.v1.cond', content)\n",
    "    with open(tf_slim_path, 'w') as file:\n",
    "        file.write(content)\n",
    "    print(f\"File {tf_slim_path} updated successfully.\")\n",
    "else:\n",
    "    print(f\"Warning: Could not find {tf_slim_path}. Please verify the path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted /root/MultiAgent/FTCTraining/FTCYolo.v7i.tfrecord.zip to /root/MultiAgent/FTCTraining/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Define dataset variables\n",
    "# Assuming you have already downloaded 'samples-specimens.tfrecord.zip' locally\n",
    "# Update the path to where your .tfrecord.zip is located\n",
    "TFR_ZIP_PATH = \"/root/MultiAgent/FTCTraining/FTCYolo.v7i.tfrecord.zip\"  # Adjust if different\n",
    "EXTRACT_DIR = os.path.join(HOMEFOLDER, 'train')\n",
    "\n",
    "# Do NOT remove the 'models' directory here, as it contains the cloned TensorFlow models repository\n",
    "# Commenting out the deletion of MODELS_DIR:\n",
    "# if os.path.exists(MODELS_DIR):\n",
    "#     shutil.rmtree(MODELS_DIR)\n",
    "#     print(f\"Removed existing directory: {MODELS_DIR}\")\n",
    "\n",
    "# Unzip the TFRecord file\n",
    "if os.path.exists(TFR_ZIP_PATH):\n",
    "    with zipfile.ZipFile(TFR_ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(f\"Extracted {TFR_ZIP_PATH} to {EXTRACT_DIR}\")\n",
    "else:\n",
    "    print(f\"TFRecord zip file not found at {TFR_ZIP_PATH}. Please upload it to the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Record File: /root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord\n",
      "Validation Record File: \n",
      "Label Map File: /root/MultiAgent/FTCTraining/train/train/samples-specimens_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "\n",
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename\n",
    "\n",
    "def set_tfrecord_variables(directory):\n",
    "    train_record_fname = ''\n",
    "    val_record_fname = ''\n",
    "    label_map_pbtxt_fname = ''\n",
    "\n",
    "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
    "        if '/train/' in tfrecord_file:\n",
    "            train_record_fname = tfrecord_file\n",
    "        elif '/valid/' in tfrecord_file:\n",
    "            val_record_fname = tfrecord_file\n",
    "        elif '/test/' in tfrecord_file:\n",
    "            pass\n",
    "\n",
    "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
    "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
    "\n",
    "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
    "\n",
    "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables(EXTRACT_DIR)\n",
    "\n",
    "print(\"Train Record File:\", train_record_fname)\n",
    "print(\"Validation Record File:\", val_record_fname)\n",
    "print(\"Label Map File:\", label_map_pbtxt_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: /root/MultiAgent/FTCTraining/models/mymodel\n",
      "--2025-02-01 11:13:32--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 18.160.200.119, 18.160.200.4, 18.160.200.95, ...\n",
      "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|18.160.200.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46042990 (44M) [application/x-gzip]\n",
      "Saving to: /root/MultiAgent/FTCTraining/models/mymodel/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
      "\n",
      "limelight_ssd_mobil 100%[===================>]  43.91M  20.1MB/s    in 2.2s    \n",
      "\n",
      "2025-02-01 11:13:35 (20.1 MB/s) - /root/MultiAgent/FTCTraining/models/mymodel/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz saved [46042990/46042990]\n",
      "\n",
      "Downloaded limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz to /root/MultiAgent/FTCTraining/models/mymodel\n",
      "Extracted limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz in /root/MultiAgent/FTCTraining/models/mymodel\n",
      "--2025-02-01 11:13:36--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
      "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 18.160.200.95, 18.160.200.4, 18.160.200.119, ...\n",
      "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|18.160.200.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4681 (4.6K) [binary/octet-stream]\n",
      "Saving to: /root/MultiAgent/FTCTraining/models/mymodel/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
      "\n",
      "limelight_ssd_mobil 100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-02-01 11:13:36 (201 MB/s) - /root/MultiAgent/FTCTraining/models/mymodel/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config saved [4681/4681]\n",
      "\n",
      "Downloaded limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config to /root/MultiAgent/FTCTraining/models/mymodel\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Define the chosen model and its configurations\n",
    "chosen_model = 'ssd-mobilenet-v2'\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "}\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "\n",
    "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
    "mymodel_dir = os.path.join(MODELS_DIR, 'mymodel')\n",
    "os.makedirs(mymodel_dir, exist_ok=True)\n",
    "print(f\"Created directory: {mymodel_dir}\")\n",
    "\n",
    "# Download pre-trained model weights\n",
    "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
    "checkpoint_tar_path = os.path.join(mymodel_dir, pretrained_checkpoint)\n",
    "\n",
    "if not os.path.exists(checkpoint_tar_path):\n",
    "    !wget {download_tar} -P {mymodel_dir}\n",
    "    print(f\"Downloaded {pretrained_checkpoint} to {mymodel_dir}\")\n",
    "else:\n",
    "    print(f\"Pre-trained checkpoint already exists at {checkpoint_tar_path}\")\n",
    "\n",
    "# Extract the checkpoint\n",
    "with tarfile.open(checkpoint_tar_path) as tar:\n",
    "    tar.extractall(path=mymodel_dir)\n",
    "    print(f\"Extracted {pretrained_checkpoint} in {mymodel_dir}\")\n",
    "\n",
    "# Download training configuration file for model\n",
    "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
    "pipeline_config_path = os.path.join(mymodel_dir, base_pipeline_file)\n",
    "\n",
    "if not os.path.exists(pipeline_config_path):\n",
    "    !wget {download_config} -P {mymodel_dir}\n",
    "    print(f\"Downloaded {base_pipeline_file} to {mymodel_dir}\")\n",
    "else:\n",
    "    print(f\"Pipeline config already exists at {pipeline_config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:13:36.791557: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-01 11:13:36.815796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-01 11:13:36.815819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-01 11:13:36.816513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 11:13:36.821500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-01 11:13:37.418321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 3\n",
      "Classes: ['blue-specimen', 'red-specimen', 'yellow-specimen']\n",
      "Labels file created at: /root/MultiAgent/FTCTraining/limelight_neural_detector_labels.txt\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "\n",
    "def get_classes(pbtxt_fname):\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    class_names = [category['name'] for category in category_index.values()]\n",
    "    return class_names\n",
    "\n",
    "def create_label_file(filename, labels):\n",
    "    with open(filename, 'w') as file:\n",
    "        for label in labels:\n",
    "            file.write(label + '\\n')\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "classes = get_classes(label_map_pbtxt_fname)\n",
    "\n",
    "print('Total classes:', num_classes)\n",
    "print('Classes:', classes)\n",
    "\n",
    "# Generate labels file\n",
    "labels_file_path = os.path.join(HOMEFOLDER, \"limelight_neural_detector_labels.txt\")\n",
    "create_label_file(labels_file_path, classes)\n",
    "print(f\"Labels file created at: {labels_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing custom configuration file...\n",
      "Custom pipeline configuration written to: /root/MultiAgent/FTCTraining/models/mymodel/pipeline_file.config\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "num_steps = 40000\n",
    "checkpoint_every = 2000\n",
    "batch_size = 16\n",
    "\n",
    "# Paths\n",
    "fine_tune_checkpoint = os.path.join(mymodel_dir, model_name, 'checkpoint/ckpt-0')  # Adjust if necessary\n",
    "\n",
    "# Custom pipeline configuration file\n",
    "custom_pipeline_config = os.path.join(HOMEFOLDER, 'models/mymodel', 'pipeline_file.config')\n",
    "\n",
    "print('Writing custom configuration file...')\n",
    "\n",
    "with open(pipeline_config_path, 'r') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(custom_pipeline_config, 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               f'fine_tune_checkpoint: \"{fine_tune_checkpoint}\"', s)\n",
    "\n",
    "    # Set tfrecord files for train and test datasets\n",
    "    s = re.sub(\n",
    "        r'input_path: \".*?PATH_TO_BE_CONFIGURED/train.*?\"',\n",
    "        f'input_path: \"{train_record_fname}\"', s)\n",
    "    s = re.sub(\n",
    "        r'input_path: \".*?PATH_TO_BE_CONFIGURED/val.*?\"',\n",
    "        f'input_path: \"{val_record_fname}\"', s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', f'label_map_path: \"{label_map_pbtxt_fname}\"', s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               f'batch_size: {batch_size}', s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               f'num_steps: {num_steps}', s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               f'num_classes: {num_classes}', s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"',\n",
    "        'fine_tune_checkpoint_type: \"detection\"', s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "        s = re.sub('learning_rate_base: .8',\n",
    "                   'learning_rate_base: 0.004', s)\n",
    "        s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                   'warmup_learning_rate: 0.0016666', s)\n",
    "\n",
    "    # Write the modified config to the custom pipeline file\n",
    "    f.write(s)\n",
    "\n",
    "print(f\"Custom pipeline configuration written to: {custom_pipeline_config}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found Training TFRecord: /root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord\n",
      " Found Validation TFRecord: /root/MultiAgent/FTCTraining/valid/samples-specimens.tfrecord\n",
      " Found Label Map: /root/MultiAgent/FTCTraining/train/train/samples-specimens_label_map.pbtxt\n",
      " Found Pipeline Config: /root/MultiAgent/FTCTraining/models/mymodel/pipeline_file.config\n"
     ]
    }
   ],
   "source": [
    "val_record_fname = \"/root/MultiAgent/FTCTraining/valid/samples-specimens.tfrecord\"\n",
    "\n",
    "def validate_paths():\n",
    "    required_files = {\n",
    "        \"Training TFRecord\": train_record_fname,\n",
    "        \"Validation TFRecord\": val_record_fname,\n",
    "        \"Label Map\": label_map_pbtxt_fname,\n",
    "        \"Pipeline Config\": custom_pipeline_config\n",
    "    }\n",
    "\n",
    "    missing = False\n",
    "    for name, path in required_files.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\" Missing {name}: {path}\")\n",
    "            missing = True\n",
    "        else:\n",
    "            print(f\" Found {name}: {path}\")\n",
    "\n",
    "    if missing:\n",
    "        raise FileNotFoundError(\"Missing required training files. Check paths above.\")\n",
    "\n",
    "validate_paths()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/MultiAgent/FTCTraining/models/research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:13:38.508315: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-01 11:13:38.536248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-01 11:13:38.536303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-01 11:13:38.537037: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 11:13:38.541295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-01 11:13:39.160001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-01 11:13:41.068710: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.099147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.099251: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "WARNING:tensorflow:From /root/MultiAgent/FTCTraining/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "W0201 11:13:41.099450 140527786252096 deprecation.py:50] From /root/MultiAgent/FTCTraining/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "2025-02-01 11:13:41.103324: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.103411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.103454: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.314173: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.314280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.314301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:13:41.314350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:13:41.314380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
      "I0201 11:13:41.479861 140527786252096 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/device:GPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
      "I0201 11:13:41.480037 140527786252096 collective_all_reduce_strategy.py:446] Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 40000\n",
      "I0201 11:13:41.482553 140527786252096 config_util.py:552] Maybe overwriting train_steps: 40000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0201 11:13:41.482667 140527786252096 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0201 11:13:41.507187 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord']\n",
      "I0201 11:13:41.520478 140527786252096 dataset_builder.py:162] Reading unweighted datasets: ['/root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord']\n",
      "I0201 11:13:41.520644 140527786252096 dataset_builder.py:79] Reading record datasets for input file: ['/root/MultiAgent/FTCTraining/train/train/samples-specimens.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0201 11:13:41.520718 140527786252096 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0201 11:13:41.520772 140527786252096 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0201 11:13:41.530109 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0201 11:13:41.543992 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0201 11:13:44.714701 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0201 11:13:46.362213 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0201 11:13:47.630831 140527786252096 deprecation.py:50] From /root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/root/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "I0201 11:13:53.101676 140516616296128 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852180 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852344 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852421 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852499 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852560 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:13:53.852622 140516616296128 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "I0201 11:13:57.199857 140516616296128 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "2025-02-01 11:14:00.052565: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "I0201 11:14:04.005601 140516071032512 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0201 11:14:07.418210 140516071032512 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0201 11:14:10.363338 140516071032512 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "I0201 11:14:13.364246 140516071032512 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:Step 100 per-step time 0.493s\n",
      "I0201 11:14:52.897895 140527786252096 model_lib_v2.py:705] Step 100 per-step time 0.493s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5130751,\n",
      " 'Loss/localization_loss': 0.6066622,\n",
      " 'Loss/regularization_loss': 0.08524057,\n",
      " 'Loss/total_loss': 1.204978,\n",
      " 'learning_rate': 0.00178327}\n",
      "I0201 11:14:52.905008 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.5130751,\n",
      " 'Loss/localization_loss': 0.6066622,\n",
      " 'Loss/regularization_loss': 0.08524057,\n",
      " 'Loss/total_loss': 1.204978,\n",
      " 'learning_rate': 0.00178327}\n",
      "INFO:tensorflow:Step 200 per-step time 0.229s\n",
      "I0201 11:15:15.595457 140527786252096 model_lib_v2.py:705] Step 200 per-step time 0.229s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25125363,\n",
      " 'Loss/localization_loss': 0.45929968,\n",
      " 'Loss/regularization_loss': 0.08525175,\n",
      " 'Loss/total_loss': 0.79580504,\n",
      " 'learning_rate': 0.0018999401}\n",
      "I0201 11:15:15.595682 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.25125363,\n",
      " 'Loss/localization_loss': 0.45929968,\n",
      " 'Loss/regularization_loss': 0.08525175,\n",
      " 'Loss/total_loss': 0.79580504,\n",
      " 'learning_rate': 0.0018999401}\n",
      "INFO:tensorflow:Step 300 per-step time 0.213s\n",
      "I0201 11:15:36.894610 140527786252096 model_lib_v2.py:705] Step 300 per-step time 0.213s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27454913,\n",
      " 'Loss/localization_loss': 0.5121659,\n",
      " 'Loss/regularization_loss': 0.085254356,\n",
      " 'Loss/total_loss': 0.8719694,\n",
      " 'learning_rate': 0.00201661}\n",
      "I0201 11:15:36.895213 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.27454913,\n",
      " 'Loss/localization_loss': 0.5121659,\n",
      " 'Loss/regularization_loss': 0.085254356,\n",
      " 'Loss/total_loss': 0.8719694,\n",
      " 'learning_rate': 0.00201661}\n",
      "INFO:tensorflow:Step 400 per-step time 0.247s\n",
      "I0201 11:16:01.589491 140527786252096 model_lib_v2.py:705] Step 400 per-step time 0.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2214776,\n",
      " 'Loss/localization_loss': 0.3710347,\n",
      " 'Loss/regularization_loss': 0.08525046,\n",
      " 'Loss/total_loss': 0.67776275,\n",
      " 'learning_rate': 0.00213328}\n",
      "I0201 11:16:01.590954 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.2214776,\n",
      " 'Loss/localization_loss': 0.3710347,\n",
      " 'Loss/regularization_loss': 0.08525046,\n",
      " 'Loss/total_loss': 0.67776275,\n",
      " 'learning_rate': 0.00213328}\n",
      "INFO:tensorflow:Step 500 per-step time 0.247s\n",
      "I0201 11:16:26.249298 140527786252096 model_lib_v2.py:705] Step 500 per-step time 0.247s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16896781,\n",
      " 'Loss/localization_loss': 0.15709999,\n",
      " 'Loss/regularization_loss': 0.08524589,\n",
      " 'Loss/total_loss': 0.4113137,\n",
      " 'learning_rate': 0.00224995}\n",
      "I0201 11:16:26.249851 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.16896781,\n",
      " 'Loss/localization_loss': 0.15709999,\n",
      " 'Loss/regularization_loss': 0.08524589,\n",
      " 'Loss/total_loss': 0.4113137,\n",
      " 'learning_rate': 0.00224995}\n",
      "INFO:tensorflow:Step 600 per-step time 0.260s\n",
      "I0201 11:16:52.230200 140527786252096 model_lib_v2.py:705] Step 600 per-step time 0.260s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17639124,\n",
      " 'Loss/localization_loss': 0.1655469,\n",
      " 'Loss/regularization_loss': 0.08523933,\n",
      " 'Loss/total_loss': 0.42717746,\n",
      " 'learning_rate': 0.00236662}\n",
      "I0201 11:16:52.230401 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.17639124,\n",
      " 'Loss/localization_loss': 0.1655469,\n",
      " 'Loss/regularization_loss': 0.08523933,\n",
      " 'Loss/total_loss': 0.42717746,\n",
      " 'learning_rate': 0.00236662}\n",
      "INFO:tensorflow:Step 700 per-step time 0.249s\n",
      "I0201 11:17:17.174073 140527786252096 model_lib_v2.py:705] Step 700 per-step time 0.249s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17247218,\n",
      " 'Loss/localization_loss': 0.29713893,\n",
      " 'Loss/regularization_loss': 0.08523189,\n",
      " 'Loss/total_loss': 0.554843,\n",
      " 'learning_rate': 0.0024832902}\n",
      "I0201 11:17:17.174311 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.17247218,\n",
      " 'Loss/localization_loss': 0.29713893,\n",
      " 'Loss/regularization_loss': 0.08523189,\n",
      " 'Loss/total_loss': 0.554843,\n",
      " 'learning_rate': 0.0024832902}\n",
      "INFO:tensorflow:Step 800 per-step time 0.254s\n",
      "I0201 11:17:42.570198 140527786252096 model_lib_v2.py:705] Step 800 per-step time 0.254s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.174643,\n",
      " 'Loss/localization_loss': 0.14227179,\n",
      " 'Loss/regularization_loss': 0.08522324,\n",
      " 'Loss/total_loss': 0.40213805,\n",
      " 'learning_rate': 0.0025999602}\n",
      "I0201 11:17:42.570757 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.174643,\n",
      " 'Loss/localization_loss': 0.14227179,\n",
      " 'Loss/regularization_loss': 0.08522324,\n",
      " 'Loss/total_loss': 0.40213805,\n",
      " 'learning_rate': 0.0025999602}\n",
      "INFO:tensorflow:Step 900 per-step time 0.248s\n",
      "I0201 11:18:07.342036 140527786252096 model_lib_v2.py:705] Step 900 per-step time 0.248s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19958025,\n",
      " 'Loss/localization_loss': 0.18852891,\n",
      " 'Loss/regularization_loss': 0.08521452,\n",
      " 'Loss/total_loss': 0.47332367,\n",
      " 'learning_rate': 0.0027166302}\n",
      "I0201 11:18:07.342530 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.19958025,\n",
      " 'Loss/localization_loss': 0.18852891,\n",
      " 'Loss/regularization_loss': 0.08521452,\n",
      " 'Loss/total_loss': 0.47332367,\n",
      " 'learning_rate': 0.0027166302}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.249s\n",
      "I0201 11:18:32.226350 140527786252096 model_lib_v2.py:705] Step 1000 per-step time 0.249s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10679637,\n",
      " 'Loss/localization_loss': 0.1005809,\n",
      " 'Loss/regularization_loss': 0.08520465,\n",
      " 'Loss/total_loss': 0.29258192,\n",
      " 'learning_rate': 0.0028333003}\n",
      "I0201 11:18:32.226662 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.10679637,\n",
      " 'Loss/localization_loss': 0.1005809,\n",
      " 'Loss/regularization_loss': 0.08520465,\n",
      " 'Loss/total_loss': 0.29258192,\n",
      " 'learning_rate': 0.0028333003}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.249s\n",
      "I0201 11:18:57.131855 140527786252096 model_lib_v2.py:705] Step 1100 per-step time 0.249s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15214285,\n",
      " 'Loss/localization_loss': 0.2014619,\n",
      " 'Loss/regularization_loss': 0.08519456,\n",
      " 'Loss/total_loss': 0.4387993,\n",
      " 'learning_rate': 0.0029499703}\n",
      "I0201 11:18:57.132345 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15214285,\n",
      " 'Loss/localization_loss': 0.2014619,\n",
      " 'Loss/regularization_loss': 0.08519456,\n",
      " 'Loss/total_loss': 0.4387993,\n",
      " 'learning_rate': 0.0029499703}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.265s\n",
      "I0201 11:19:23.575634 140527786252096 model_lib_v2.py:705] Step 1200 per-step time 0.265s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12487462,\n",
      " 'Loss/localization_loss': 0.100585155,\n",
      " 'Loss/regularization_loss': 0.085183136,\n",
      " 'Loss/total_loss': 0.31064293,\n",
      " 'learning_rate': 0.0030666403}\n",
      "I0201 11:19:23.576161 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.12487462,\n",
      " 'Loss/localization_loss': 0.100585155,\n",
      " 'Loss/regularization_loss': 0.085183136,\n",
      " 'Loss/total_loss': 0.31064293,\n",
      " 'learning_rate': 0.0030666403}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.256s\n",
      "I0201 11:19:49.154658 140527786252096 model_lib_v2.py:705] Step 1300 per-step time 0.256s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1899299,\n",
      " 'Loss/localization_loss': 0.12811546,\n",
      " 'Loss/regularization_loss': 0.08517128,\n",
      " 'Loss/total_loss': 0.40321666,\n",
      " 'learning_rate': 0.0031833102}\n",
      "I0201 11:19:49.155011 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.1899299,\n",
      " 'Loss/localization_loss': 0.12811546,\n",
      " 'Loss/regularization_loss': 0.08517128,\n",
      " 'Loss/total_loss': 0.40321666,\n",
      " 'learning_rate': 0.0031833102}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.250s\n",
      "I0201 11:20:14.172734 140527786252096 model_lib_v2.py:705] Step 1400 per-step time 0.250s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.093298115,\n",
      " 'Loss/localization_loss': 0.094545536,\n",
      " 'Loss/regularization_loss': 0.08515883,\n",
      " 'Loss/total_loss': 0.27300248,\n",
      " 'learning_rate': 0.0032999802}\n",
      "I0201 11:20:14.173126 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.093298115,\n",
      " 'Loss/localization_loss': 0.094545536,\n",
      " 'Loss/regularization_loss': 0.08515883,\n",
      " 'Loss/total_loss': 0.27300248,\n",
      " 'learning_rate': 0.0032999802}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.248s\n",
      "I0201 11:20:38.924975 140527786252096 model_lib_v2.py:705] Step 1500 per-step time 0.248s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10796965,\n",
      " 'Loss/localization_loss': 0.0879023,\n",
      " 'Loss/regularization_loss': 0.08514691,\n",
      " 'Loss/total_loss': 0.28101885,\n",
      " 'learning_rate': 0.0034166502}\n",
      "I0201 11:20:38.925244 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.10796965,\n",
      " 'Loss/localization_loss': 0.0879023,\n",
      " 'Loss/regularization_loss': 0.08514691,\n",
      " 'Loss/total_loss': 0.28101885,\n",
      " 'learning_rate': 0.0034166502}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.255s\n",
      "I0201 11:21:04.393836 140527786252096 model_lib_v2.py:705] Step 1600 per-step time 0.255s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1631651,\n",
      " 'Loss/localization_loss': 0.085251145,\n",
      " 'Loss/regularization_loss': 0.08513343,\n",
      " 'Loss/total_loss': 0.33354968,\n",
      " 'learning_rate': 0.0035333203}\n",
      "I0201 11:21:04.394359 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.1631651,\n",
      " 'Loss/localization_loss': 0.085251145,\n",
      " 'Loss/regularization_loss': 0.08513343,\n",
      " 'Loss/total_loss': 0.33354968,\n",
      " 'learning_rate': 0.0035333203}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.263s\n",
      "I0201 11:21:30.719499 140527786252096 model_lib_v2.py:705] Step 1700 per-step time 0.263s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07004556,\n",
      " 'Loss/localization_loss': 0.07901691,\n",
      " 'Loss/regularization_loss': 0.085120544,\n",
      " 'Loss/total_loss': 0.23418301,\n",
      " 'learning_rate': 0.00364999}\n",
      "I0201 11:21:30.720921 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.07004556,\n",
      " 'Loss/localization_loss': 0.07901691,\n",
      " 'Loss/regularization_loss': 0.085120544,\n",
      " 'Loss/total_loss': 0.23418301,\n",
      " 'learning_rate': 0.00364999}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.284s\n",
      "I0201 11:21:59.095970 140527786252096 model_lib_v2.py:705] Step 1800 per-step time 0.284s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10111993,\n",
      " 'Loss/localization_loss': 0.079059154,\n",
      " 'Loss/regularization_loss': 0.08510508,\n",
      " 'Loss/total_loss': 0.26528418,\n",
      " 'learning_rate': 0.00376666}\n",
      "I0201 11:21:59.096976 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.10111993,\n",
      " 'Loss/localization_loss': 0.079059154,\n",
      " 'Loss/regularization_loss': 0.08510508,\n",
      " 'Loss/total_loss': 0.26528418,\n",
      " 'learning_rate': 0.00376666}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.252s\n",
      "I0201 11:22:24.291683 140527786252096 model_lib_v2.py:705] Step 1900 per-step time 0.252s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13471434,\n",
      " 'Loss/localization_loss': 0.080000214,\n",
      " 'Loss/regularization_loss': 0.08509194,\n",
      " 'Loss/total_loss': 0.2998065,\n",
      " 'learning_rate': 0.0038833302}\n",
      "I0201 11:22:24.291872 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13471434,\n",
      " 'Loss/localization_loss': 0.080000214,\n",
      " 'Loss/regularization_loss': 0.08509194,\n",
      " 'Loss/total_loss': 0.2998065,\n",
      " 'learning_rate': 0.0038833302}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.245s\n",
      "I0201 11:22:48.808215 140527786252096 model_lib_v2.py:705] Step 2000 per-step time 0.245s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07209675,\n",
      " 'Loss/localization_loss': 0.077191465,\n",
      " 'Loss/regularization_loss': 0.08507687,\n",
      " 'Loss/total_loss': 0.23436508,\n",
      " 'learning_rate': 0.004}\n",
      "I0201 11:22:48.808568 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.07209675,\n",
      " 'Loss/localization_loss': 0.077191465,\n",
      " 'Loss/regularization_loss': 0.08507687,\n",
      " 'Loss/total_loss': 0.23436508,\n",
      " 'learning_rate': 0.004}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.263s\n",
      "I0201 11:23:15.094048 140527786252096 model_lib_v2.py:705] Step 2100 per-step time 0.263s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.077375814,\n",
      " 'Loss/localization_loss': 0.046354625,\n",
      " 'Loss/regularization_loss': 0.085061036,\n",
      " 'Loss/total_loss': 0.20879146,\n",
      " 'learning_rate': 0.0039999573}\n",
      "I0201 11:23:15.094882 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.077375814,\n",
      " 'Loss/localization_loss': 0.046354625,\n",
      " 'Loss/regularization_loss': 0.085061036,\n",
      " 'Loss/total_loss': 0.20879146,\n",
      " 'learning_rate': 0.0039999573}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.261s\n",
      "I0201 11:23:41.237274 140527786252096 model_lib_v2.py:705] Step 2200 per-step time 0.261s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07579711,\n",
      " 'Loss/localization_loss': 0.10573158,\n",
      " 'Loss/regularization_loss': 0.085043825,\n",
      " 'Loss/total_loss': 0.2665725,\n",
      " 'learning_rate': 0.003999829}\n",
      "I0201 11:23:41.237531 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.07579711,\n",
      " 'Loss/localization_loss': 0.10573158,\n",
      " 'Loss/regularization_loss': 0.085043825,\n",
      " 'Loss/total_loss': 0.2665725,\n",
      " 'learning_rate': 0.003999829}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.284s\n",
      "I0201 11:24:09.617937 140527786252096 model_lib_v2.py:705] Step 2300 per-step time 0.284s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08624415,\n",
      " 'Loss/localization_loss': 0.048999358,\n",
      " 'Loss/regularization_loss': 0.085028216,\n",
      " 'Loss/total_loss': 0.22027172,\n",
      " 'learning_rate': 0.0039996146}\n",
      "I0201 11:24:09.618789 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.08624415,\n",
      " 'Loss/localization_loss': 0.048999358,\n",
      " 'Loss/regularization_loss': 0.085028216,\n",
      " 'Loss/total_loss': 0.22027172,\n",
      " 'learning_rate': 0.0039996146}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.264s\n",
      "I0201 11:24:36.028248 140527786252096 model_lib_v2.py:705] Step 2400 per-step time 0.264s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0895941,\n",
      " 'Loss/localization_loss': 0.1496375,\n",
      " 'Loss/regularization_loss': 0.08501138,\n",
      " 'Loss/total_loss': 0.324243,\n",
      " 'learning_rate': 0.003999315}\n",
      "I0201 11:24:36.029324 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.0895941,\n",
      " 'Loss/localization_loss': 0.1496375,\n",
      " 'Loss/regularization_loss': 0.08501138,\n",
      " 'Loss/total_loss': 0.324243,\n",
      " 'learning_rate': 0.003999315}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.289s\n",
      "I0201 11:25:04.906478 140527786252096 model_lib_v2.py:705] Step 2500 per-step time 0.289s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07792945,\n",
      " 'Loss/localization_loss': 0.0993663,\n",
      " 'Loss/regularization_loss': 0.08499445,\n",
      " 'Loss/total_loss': 0.26229018,\n",
      " 'learning_rate': 0.003998929}\n",
      "I0201 11:25:04.906685 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.07792945,\n",
      " 'Loss/localization_loss': 0.0993663,\n",
      " 'Loss/regularization_loss': 0.08499445,\n",
      " 'Loss/total_loss': 0.26229018,\n",
      " 'learning_rate': 0.003998929}\n",
      "INFO:tensorflow:Step 2600 per-step time 0.287s\n",
      "I0201 11:25:33.596269 140527786252096 model_lib_v2.py:705] Step 2600 per-step time 0.287s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07512449,\n",
      " 'Loss/localization_loss': 0.05874996,\n",
      " 'Loss/regularization_loss': 0.08497751,\n",
      " 'Loss/total_loss': 0.21885195,\n",
      " 'learning_rate': 0.003998458}\n",
      "I0201 11:25:33.596848 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.07512449,\n",
      " 'Loss/localization_loss': 0.05874996,\n",
      " 'Loss/regularization_loss': 0.08497751,\n",
      " 'Loss/total_loss': 0.21885195,\n",
      " 'learning_rate': 0.003998458}\n",
      "INFO:tensorflow:Step 2700 per-step time 0.264s\n",
      "I0201 11:26:00.017169 140527786252096 model_lib_v2.py:705] Step 2700 per-step time 0.264s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09793076,\n",
      " 'Loss/localization_loss': 0.052124728,\n",
      " 'Loss/regularization_loss': 0.08496128,\n",
      " 'Loss/total_loss': 0.23501676,\n",
      " 'learning_rate': 0.0039979015}\n",
      "I0201 11:26:00.017437 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.09793076,\n",
      " 'Loss/localization_loss': 0.052124728,\n",
      " 'Loss/regularization_loss': 0.08496128,\n",
      " 'Loss/total_loss': 0.23501676,\n",
      " 'learning_rate': 0.0039979015}\n",
      "INFO:tensorflow:Step 2800 per-step time 0.262s\n",
      "I0201 11:26:26.192979 140527786252096 model_lib_v2.py:705] Step 2800 per-step time 0.262s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12418041,\n",
      " 'Loss/localization_loss': 0.076188505,\n",
      " 'Loss/regularization_loss': 0.08494472,\n",
      " 'Loss/total_loss': 0.28531364,\n",
      " 'learning_rate': 0.0039972593}\n",
      "I0201 11:26:26.193552 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.12418041,\n",
      " 'Loss/localization_loss': 0.076188505,\n",
      " 'Loss/regularization_loss': 0.08494472,\n",
      " 'Loss/total_loss': 0.28531364,\n",
      " 'learning_rate': 0.0039972593}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.266s\n",
      "I0201 11:26:52.746754 140527786252096 model_lib_v2.py:705] Step 2900 per-step time 0.266s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.0801963,\n",
      " 'Loss/localization_loss': 0.048522197,\n",
      " 'Loss/regularization_loss': 0.08492777,\n",
      " 'Loss/total_loss': 0.21364626,\n",
      " 'learning_rate': 0.0039965315}\n",
      "I0201 11:26:52.746963 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.0801963,\n",
      " 'Loss/localization_loss': 0.048522197,\n",
      " 'Loss/regularization_loss': 0.08492777,\n",
      " 'Loss/total_loss': 0.21364626,\n",
      " 'learning_rate': 0.0039965315}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.268s\n",
      "I0201 11:27:19.557327 140527786252096 model_lib_v2.py:705] Step 3000 per-step time 0.268s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.085762054,\n",
      " 'Loss/localization_loss': 0.0367193,\n",
      " 'Loss/regularization_loss': 0.08491058,\n",
      " 'Loss/total_loss': 0.20739193,\n",
      " 'learning_rate': 0.003995718}\n",
      "I0201 11:27:19.557561 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.085762054,\n",
      " 'Loss/localization_loss': 0.0367193,\n",
      " 'Loss/regularization_loss': 0.08491058,\n",
      " 'Loss/total_loss': 0.20739193,\n",
      " 'learning_rate': 0.003995718}\n",
      "INFO:tensorflow:Step 3100 per-step time 0.275s\n",
      "I0201 11:27:47.102196 140527786252096 model_lib_v2.py:705] Step 3100 per-step time 0.275s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14202727,\n",
      " 'Loss/localization_loss': 0.24088557,\n",
      " 'Loss/regularization_loss': 0.08489347,\n",
      " 'Loss/total_loss': 0.4678063,\n",
      " 'learning_rate': 0.0039948192}\n",
      "I0201 11:27:47.102493 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.14202727,\n",
      " 'Loss/localization_loss': 0.24088557,\n",
      " 'Loss/regularization_loss': 0.08489347,\n",
      " 'Loss/total_loss': 0.4678063,\n",
      " 'learning_rate': 0.0039948192}\n",
      "INFO:tensorflow:Step 3200 per-step time 0.283s\n",
      "I0201 11:28:15.390492 140527786252096 model_lib_v2.py:705] Step 3200 per-step time 0.283s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13896202,\n",
      " 'Loss/localization_loss': 0.050688054,\n",
      " 'Loss/regularization_loss': 0.08487694,\n",
      " 'Loss/total_loss': 0.274527,\n",
      " 'learning_rate': 0.003993835}\n",
      "I0201 11:28:15.391371 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13896202,\n",
      " 'Loss/localization_loss': 0.050688054,\n",
      " 'Loss/regularization_loss': 0.08487694,\n",
      " 'Loss/total_loss': 0.274527,\n",
      " 'learning_rate': 0.003993835}\n",
      "INFO:tensorflow:Step 3300 per-step time 0.269s\n",
      "I0201 11:28:42.255528 140527786252096 model_lib_v2.py:705] Step 3300 per-step time 0.269s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09532701,\n",
      " 'Loss/localization_loss': 0.11411652,\n",
      " 'Loss/regularization_loss': 0.084859215,\n",
      " 'Loss/total_loss': 0.29430276,\n",
      " 'learning_rate': 0.003992765}\n",
      "I0201 11:28:42.256572 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.09532701,\n",
      " 'Loss/localization_loss': 0.11411652,\n",
      " 'Loss/regularization_loss': 0.084859215,\n",
      " 'Loss/total_loss': 0.29430276,\n",
      " 'learning_rate': 0.003992765}\n",
      "INFO:tensorflow:Step 3400 per-step time 0.274s\n",
      "I0201 11:29:09.608088 140527786252096 model_lib_v2.py:705] Step 3400 per-step time 0.274s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13499403,\n",
      " 'Loss/localization_loss': 0.12778914,\n",
      " 'Loss/regularization_loss': 0.08484107,\n",
      " 'Loss/total_loss': 0.34762424,\n",
      " 'learning_rate': 0.00399161}\n",
      "I0201 11:29:09.608439 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13499403,\n",
      " 'Loss/localization_loss': 0.12778914,\n",
      " 'Loss/regularization_loss': 0.08484107,\n",
      " 'Loss/total_loss': 0.34762424,\n",
      " 'learning_rate': 0.00399161}\n",
      "INFO:tensorflow:Step 3500 per-step time 0.252s\n",
      "I0201 11:29:34.842092 140527786252096 model_lib_v2.py:705] Step 3500 per-step time 0.252s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09541157,\n",
      " 'Loss/localization_loss': 0.060166247,\n",
      " 'Loss/regularization_loss': 0.08482314,\n",
      " 'Loss/total_loss': 0.24040094,\n",
      " 'learning_rate': 0.0039903694}\n",
      "I0201 11:29:34.842338 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.09541157,\n",
      " 'Loss/localization_loss': 0.060166247,\n",
      " 'Loss/regularization_loss': 0.08482314,\n",
      " 'Loss/total_loss': 0.24040094,\n",
      " 'learning_rate': 0.0039903694}\n",
      "INFO:tensorflow:Step 3600 per-step time 0.258s\n",
      "I0201 11:30:00.632172 140527786252096 model_lib_v2.py:705] Step 3600 per-step time 0.258s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.059341915,\n",
      " 'Loss/localization_loss': 0.033056367,\n",
      " 'Loss/regularization_loss': 0.08480576,\n",
      " 'Loss/total_loss': 0.17720404,\n",
      " 'learning_rate': 0.003989044}\n",
      "I0201 11:30:00.637323 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.059341915,\n",
      " 'Loss/localization_loss': 0.033056367,\n",
      " 'Loss/regularization_loss': 0.08480576,\n",
      " 'Loss/total_loss': 0.17720404,\n",
      " 'learning_rate': 0.003989044}\n",
      "INFO:tensorflow:Step 3700 per-step time 0.261s\n",
      "I0201 11:30:26.758422 140527786252096 model_lib_v2.py:705] Step 3700 per-step time 0.261s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.080672145,\n",
      " 'Loss/localization_loss': 0.0442455,\n",
      " 'Loss/regularization_loss': 0.08478881,\n",
      " 'Loss/total_loss': 0.20970646,\n",
      " 'learning_rate': 0.003987633}\n",
      "I0201 11:30:26.758631 140527786252096 model_lib_v2.py:708] {'Loss/classification_loss': 0.080672145,\n",
      " 'Loss/localization_loss': 0.0442455,\n",
      " 'Loss/regularization_loss': 0.08478881,\n",
      " 'Loss/total_loss': 0.20970646,\n",
      " 'learning_rate': 0.003987633}\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Navigate to research directory\n",
    "%cd {RESEARCH_DIR}\n",
    "\n",
    "\n",
    "# Start training\n",
    "!python object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={custom_pipeline_config} \\\n",
    "    --model_dir={TRAINING_PROGRESS_DIR} \\\n",
    "    --alsologtostderr \\\n",
    "    --checkpoint_every_n={checkpoint_every} \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_workers=2 \\\n",
    "    --sample_1_of_n_eval_examples=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import io\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# --------------------------\n",
    "# Variables (assumed defined previously)\n",
    "# --------------------------\n",
    "# HOMEFOLDER = '/root/MultiAgent/FTCTraining/'          # (your project home folder)\n",
    "# MODELS_DIR = os.path.join(HOMEFOLDER, 'models')         # Cloned TF models repo folder\n",
    "# TRAINING_PROGRESS_DIR = os.path.join(HOMEFOLDER, 'training_progress')\n",
    "# custom_pipeline_config = os.path.join(HOMEFOLDER, 'models/mymodel', 'pipeline_file.config')\n",
    "# train_record_fname, val_record_fname, label_map_pbtxt_fname defined earlier\n",
    "\n",
    "# FINALOUTPUTFOLDER is the directory to store exported models and TFLite outputs.\n",
    "FINALOUTPUTFOLDER = os.path.join(HOMEFOLDER, 'final_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed existing directory: /root/MultiAgent/FTCTraining/final_output\n",
      "Final output folder: /root/MultiAgent/FTCTraining/final_output\n"
     ]
    }
   ],
   "source": [
    "# Remove final output folder if it exists\n",
    "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
    "    shutil.rmtree(FINALOUTPUTFOLDER)\n",
    "    print(f\"Removed existing directory: {FINALOUTPUTFOLDER}\")\n",
    "\n",
    "# Create a new final output folder\n",
    "!mkdir {FINALOUTPUTFOLDER}\n",
    "print(\"Final output folder:\", FINALOUTPUTFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:30:37.656899: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-01 11:30:38.042193: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-01 11:30:38.042248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-01 11:30:38.045541: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 11:30:38.056924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-01 11:30:39.170353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-01 11:30:42.299598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.414267: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.414354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.422602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.422695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.422732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.679132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.679304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.679329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:30:42.679368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:42.679991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0201 11:30:43.432492 139653477181248 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.342803 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.343205 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.343341 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.343415 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.343481 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0201 11:30:44.343522 139653477181248 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
      "2025-02-01 11:30:44.761410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:44.761520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:44.761573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:44.761997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:44.762026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:30:44.762063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:44.762095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-01 11:30:44.772070: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "I0201 11:30:45.260401 139653477181248 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "2025-02-01 11:30:45.557820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:45.557961: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:45.557982: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:45.558233: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:45.558260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:30:45.558311: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:45.558338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0201 11:30:45.681240 139653477181248 signature_serialization.py:156] Function `inference_fn` contains input name(s) resource with unsupported characters which will be renamed to boxpredictor_convolutionalclasshead_5_classpredictor_biasadd_readvariableop_resource in the SavedModel.\n",
      "I0201 11:30:46.186787 139653477181248 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
      "2025-02-01 11:30:46.486116: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:46.486243: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:46.486262: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:46.486745: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:46.486780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:30:46.486827: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:30:46.486857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f02d21affd0>, because it is not built.\n",
      "W0201 11:30:46.592053 139653477181248 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f02d21affd0>, because it is not built.\n",
      "I0201 11:30:52.470779 139653477181248 save.py:289] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 122). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /root/MultiAgent/FTCTraining/final_output/saved_model/assets\n",
      "I0201 11:30:54.601751 139653477181248 builder_impl.py:801] Assets written to: /root/MultiAgent/FTCTraining/final_output/saved_model/assets\n",
      "I0201 11:30:54.616032 139653477181248 fingerprinting_utils.py:49] Writing fingerprint to /root/MultiAgent/FTCTraining/final_output/saved_model/fingerprint.pb\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2. Export the TFLite Graph\n",
    "# --------------------------\n",
    "# Path to training directory (the exporter will choose the highest checkpoint)\n",
    "last_model_path = os.path.join(HOMEFOLDER, 'training_progress')\n",
    "\n",
    "# Exporter script (using the TensorFlow models repo)\n",
    "exporter_path = os.path.join(MODELS_DIR, 'research', 'object_detection', 'export_tflite_graph_tf2.py')\n",
    "output_directory = FINALOUTPUTFOLDER\n",
    "\n",
    "!python {exporter_path} \\\n",
    "    --trained_checkpoint_dir {last_model_path} \\\n",
    "    --output_directory {output_directory} \\\n",
    "    --pipeline_config_path {custom_pipeline_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:31:29.415079: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.500802: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.501195: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.514920: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.514972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.514986: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.688564: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.688617: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.688631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-01 11:31:29.688670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-01 11:31:29.688690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-01 11:31:37.786960: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-02-01 11:31:37.786994: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-02-01 11:31:37.787943: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:31:37.811103: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-02-01 11:31:37.811127: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:31:37.854317: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-02-01 11:31:37.868021: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-02-01 11:31:38.229666: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:31:38.357642: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 569707 microseconds.\n",
      "2025-02-01 11:31:38.512320: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 148, Total Ops 250, % non-converted = 59.20 %\n",
      " * 148 ARITH ops\n",
      "\n",
      "- arith.constant:  148 occurrences  (f32: 145, i32: 3)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 2)\n",
      "  (f32: 55)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 13)\n",
      "2025-02-01 11:31:38.940832: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 1.300 G  ops, equivalently 0.650 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32-bit TFLite model saved to: /root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_32bit.tflite\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Convert Exported SavedModel to 32-bit TFLite Model\n",
    "# --------------------------\n",
    "# Convert the saved_model to TFLite Flatbuffer\n",
    "saved_model_dir = os.path.join(FINALOUTPUTFOLDER, 'saved_model')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "model_path_32bit = os.path.join(FINALOUTPUTFOLDER, 'limelight_neural_detector_32bit.tflite')\n",
    "with open(model_path_32bit, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"32-bit TFLite model saved to:\", model_path_32bit)\n",
    "\n",
    "# Copy the labels file and the pipeline configuration file to the final output folder\n",
    "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
    "!cp {custom_pipeline_config} {FINALOUTPUTFOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 100 images to /root/MultiAgent/FTCTraining/extracted_samples\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Extract Sample Images from the TFRecord\n",
    "# --------------------------\n",
    "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
    "    \"\"\"Extracts images from a TFRecord file and saves them to an output folder.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    saved_images = 0\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    for raw_record in raw_dataset.take(num_samples):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        # Adjust the key below if your TFRecord uses a different name\n",
    "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
    "        saved_images += 1\n",
    "        if saved_images >= num_samples:\n",
    "            break\n",
    "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
    "\n",
    "# Define the output folder for extracted images\n",
    "extracted_sample_folder = os.path.join(HOMEFOLDER, 'extracted_samples')\n",
    "\n",
    "# Remove the sample folder if it exists\n",
    "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
    "    shutil.rmtree(extracted_sample_folder)\n",
    "    print(f\"Removed existing directory: {extracted_sample_folder}\")\n",
    "\n",
    "# Extract images from the training TFRecord\n",
    "extract_images_from_tfrecord(train_record_fname, extracted_sample_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling samples from: /root/MultiAgent/FTCTraining/extracted_samples\n",
      "Number of samples found: 100\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 6. Create a Representative Dataset for Quantization\n",
    "# --------------------------\n",
    "# Gather list of sample images from the extracted samples folder\n",
    "quant_image_list = []\n",
    "quant_image_list.extend(glob.glob(os.path.join(extracted_sample_folder, '*.jpg')))\n",
    "quant_image_list.extend(glob.glob(os.path.join(extracted_sample_folder, '*.jpeg')))\n",
    "quant_image_list.extend(glob.glob(os.path.join(extracted_sample_folder, '*.JPG')))\n",
    "quant_image_list.extend(glob.glob(os.path.join(extracted_sample_folder, '*.png')))\n",
    "quant_image_list.extend(glob.glob(os.path.join(extracted_sample_folder, '*.bmp')))\n",
    "\n",
    "print(\"Pulling samples from:\", extracted_sample_folder)\n",
    "print(\"Number of samples found:\", len(quant_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 7. Representative Data Generator Function\n",
    "# --------------------------\n",
    "# Initialize an interpreter for the 32-bit model to obtain input size details\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "# Assume input shape is [1, height, width, channels]\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "def representative_data_gen():\n",
    "    \"\"\"A generator function that yields batches for quantization calibration.\"\"\"\n",
    "    quant_num = 300  # Number of images to use for calibration\n",
    "    for i in range(quant_num):\n",
    "        pick_me = random.choice(quant_image_list)\n",
    "        print(\"Using sample:\", pick_me)\n",
    "        image = tf.io.read_file(pick_me)\n",
    "        if pick_me.lower().endswith('.jpg') or pick_me.lower().endswith('.jpeg'):\n",
    "            image = tf.io.decode_jpeg(image, channels=3)\n",
    "        elif pick_me.lower().endswith('.png'):\n",
    "            image = tf.io.decode_png(image, channels=3)\n",
    "        elif pick_me.lower().endswith('.bmp'):\n",
    "            image = tf.io.decode_bmp(image, channels=3)\n",
    "        image = tf.image.resize(image, [width, height])\n",
    "        image = tf.cast(image / 255.0, tf.float32)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning full integer quantization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:34:12.010243: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-02-01 11:34:12.010284: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-02-01 11:34:12.010426: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:34:12.033374: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-02-01 11:34:12.033399: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:34:12.094001: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-02-01 11:34:12.455400: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /root/MultiAgent/FTCTraining/final_output/saved_model\n",
      "2025-02-01 11:34:12.585554: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 575127 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 148, Total Ops 250, % non-converted = 59.20 %\n",
      " * 148 ARITH ops\n",
      "\n",
      "- arith.constant:  148 occurrences  (f32: 145, i32: 3)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 2)\n",
      "  (f32: 55)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 13)\n",
      "2025-02-01 11:34:13.054081: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 1.300 G  ops, equivalently 0.650 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_88.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_10.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_66.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_39.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_64.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_20.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_94.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_45.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_35.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_67.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_49.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_21.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_49.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_73.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_50.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_84.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_26.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_92.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_61.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_40.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_67.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_70.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_69.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_91.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_22.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_13.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_59.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_42.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_42.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_40.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_27.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_9.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_47.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_97.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_9.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_21.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_99.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_38.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_96.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_85.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_23.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_33.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_94.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_6.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_45.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_56.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_19.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_85.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_95.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_85.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_7.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_53.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_47.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_34.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_61.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_96.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_25.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_62.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_68.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_17.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_51.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_82.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_60.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_22.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_79.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_95.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_46.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_33.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_29.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_98.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_85.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_6.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_81.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_10.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_13.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_30.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_93.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_87.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_28.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_8.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_31.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_21.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_96.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_99.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_18.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_90.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_78.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_58.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_39.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_66.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_2.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_39.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_15.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_39.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_88.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_14.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_3.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_56.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_48.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_21.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_81.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_12.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_80.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_30.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_49.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_95.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_58.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_8.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_15.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_49.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_56.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_56.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_15.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_27.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_4.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_26.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_68.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_10.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_83.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_57.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_95.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_7.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_28.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_42.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_69.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_16.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_32.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_68.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_17.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_83.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_48.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_17.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_25.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_48.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_15.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_65.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_87.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_36.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_88.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_29.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_3.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_39.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_82.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_31.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_2.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_69.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_82.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_77.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_89.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_3.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_52.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_36.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_82.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_4.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_68.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_61.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_6.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_22.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_80.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_14.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_88.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_77.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_94.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_45.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_99.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_13.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_90.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_70.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_57.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_59.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_59.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_99.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_31.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_7.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_50.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_9.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_57.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_75.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_13.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_16.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_28.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_77.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_8.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_33.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_54.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_93.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_25.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_24.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_66.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_28.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_69.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_67.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_36.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_97.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_21.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_81.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_44.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_32.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_29.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_72.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_64.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_89.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_81.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_87.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_89.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_53.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_32.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_91.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_16.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_65.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_26.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_40.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_9.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_24.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_60.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_82.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_46.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_14.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_43.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_19.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_29.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_74.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_37.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_80.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_6.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_15.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_40.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_45.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_24.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_16.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_0.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_99.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_31.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_79.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_65.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_11.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_45.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_78.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_8.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_84.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_97.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_57.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_48.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_38.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_22.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_71.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_41.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_18.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_2.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_4.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_53.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_29.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_10.png\n",
      "Using sample: /root/MultiAgent/FTCTraining/extracted_samples/image_13.png\n",
      "8-bit quantized model saved to: /root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_8bit.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: FLOAT32\n",
      "2025-02-01 11:35:19.166559: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 1.300 G  ops, equivalently 0.650 G  MACs\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 8. Quantize the Model (8-bit Full Integer)\n",
    "# --------------------------\n",
    "# Reinitialize the converter using the saved model directory\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that only quantizable operations are allowed\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                                         tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "print(\"Beginning full integer quantization...\")\n",
    "tflite_quant_model = converter.convert()\n",
    "quant_model_path = os.path.join(FINALOUTPUTFOLDER, 'limelight_neural_detector_8bit.tflite')\n",
    "with open(quant_model_path, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "print(\"8-bit quantized model saved to:\", quant_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
      "100  1022  100  1022    0     0   3150      0 --:--:-- --:--:-- --:--:--  3154\n",
      "OK\n",
      "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu noble InRelease                         \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease                 \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu noble-backports InRelease               \n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64  InRelease\n",
      "Hit:6 http://security.ubuntu.com/ubuntu noble-security InRelease    \n",
      "Get:7 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [1423 B]\n",
      "Get:8 https://packages.cloud.google.com/apt coral-edgetpu-stable/main all Packages [1865 B]\n",
      "Get:9 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [6888 B]\n",
      "Fetched 10.2 kB in 1s (13.9 kB/s)\n",
      "Reading package lists... Done\n",
      "W: https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  edgetpu-compiler\n",
      "0 upgraded, 1 newly installed, 0 to remove and 115 not upgraded.\n",
      "Need to get 7913 kB of archives.\n",
      "After this operation, 31.2 MB of additional disk space will be used.\n",
      "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7913 kB]\n",
      "Fetched 7913 kB in 1s (6581 kB/s)           \n",
      "Selecting previously unselected package edgetpu-compiler.\n",
      "(Reading database ... 98498 files and directories currently installed.)\n",
      "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
      "Unpacking edgetpu-compiler (16.0) ...\n",
      "Setting up edgetpu-compiler (16.0) ...\n",
      "Processing triggers for libc-bin (2.39-0ubuntu8.3) ...\n",
      "Edge TPU Compiler version 16.0.384591198\n",
      "Started a compilation timeout timer of 180 seconds.\n",
      "\n",
      "Model compiled successfully in 855 ms.\n",
      "\n",
      "Input model: limelight_neural_detector_8bit.tflite\n",
      "Input size: 4.99MiB\n",
      "Output model: limelight_neural_detector_8bit_edgetpu.tflite\n",
      "Output size: 5.28MiB\n",
      "On-chip memory used for caching model parameters: 5.16MiB\n",
      "On-chip memory remaining for caching model parameters: 2.44MiB\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
      "Number of Edge TPU subgraphs: 1\n",
      "Total number of operations: 102\n",
      "Operation log: limelight_neural_detector_8bit_edgetpu.log\n",
      "\n",
      "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
      "Number of operations that will run on Edge TPU: 99\n",
      "Number of operations that will run on CPU: 3\n",
      "See the operation log file for individual operation details.\n",
      "Compilation child process completed within timeout period.\n",
      "Compilation succeeded! \n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 9. Compile the Quantized Model for Edge TPU\n",
    "# --------------------------\n",
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y edgetpu-compiler\n",
    "\n",
    "# Run the Edge TPU compiler on the 8-bit model\n",
    "!cd {FINALOUTPUTFOLDER} && edgetpu_compiler limelight_neural_detector_8bit.tflite && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu noble InRelease                         \u001b[0m\u001b[33m\u001b[33m\n",
      "Hit:3 http://security.ubuntu.com/ubuntu noble-security InRelease    \u001b[0m       \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease      \u001b[0m\u001b[33m\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease    \u001b[0m\u001b[33m\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64  InRelease\n",
      "Hit:7 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "115 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mhttps://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  unzip\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 115 not upgraded.\n",
      "Need to get 350 kB of archives.\n",
      "After this operation, 933 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 unzip amd64 6.0-28ubuntu4.1 [174 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 zip amd64 3.0-13ubuntu0.1 [176 kB]\n",
      "Fetched 350 kB in 1s (327 kB/s)m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 98514 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-28ubuntu4.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking unzip (6.0-28ubuntu4.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-13ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking zip (3.0-13ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up unzip (6.0-28ubuntu4.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up zip (3.0-13ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Processing triggers for man-db (2.12.0-4build2) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install zip -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/root/MultiAgent/FTCTraining/limelight_detectors.zip': No such file or directory\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/ (stored 0%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/ (stored 0%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/saved_model.pb (deflated 91%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/variables/ (stored 0%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/variables/variables.index (deflated 77%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/assets/ (stored 0%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/saved_model/fingerprint.pb (stored 0%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/pipeline_file.config (deflated 67%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_labels.txt (deflated 35%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_8bit.tflite (deflated 19%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_32bit.tflite (deflated 7%)\n",
      "  adding: root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_coral.tflite (deflated 23%)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 10. Package and Download the Final Detectors\n",
    "# --------------------------\n",
    "# Remove any previous zip file\n",
    "!rm {HOMEFOLDER}limelight_detectors.zip\n",
    "# Zip the final output folder\n",
    "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}\n",
    "\n",
    "# # If running in Google Colab, download the zip file\n",
    "# from google.colab import files\n",
    "# files.download(os.path.join(HOMEFOLDER, 'limelight_detectors.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Get:1 file:/var/nv-tensorrt-local-repo-ubuntu2404-10.7.0-cuda-12.6  InRelease [1572 B]\n",
      "Hit:2 http://security.ubuntu.com/ubuntu noble-security InRelease               \n",
      "Hit:3 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease     \n",
      "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64  InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu noble-updates InRelease\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Reading package lists... Done\n",
      "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "W: https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libedgetpu1-std\n",
      "0 upgraded, 1 newly installed, 0 to remove and 115 not upgraded.\n",
      "Need to get 387 kB of archives.\n",
      "After this operation, 1206 kB of additional disk space will be used.\n",
      "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 libedgetpu1-std amd64 16.0 [387 kB]\n",
      "Fetched 387 kB in 1s (529 kB/s)        \n",
      "Selecting previously unselected package libedgetpu1-std:amd64.\n",
      "(Reading database ... 98546 files and directories currently installed.)\n",
      "Preparing to unpack .../libedgetpu1-std_16.0_amd64.deb ...\n",
      "Unpacking libedgetpu1-std:amd64 (16.0) ...\n",
      "Setting up libedgetpu1-std:amd64 (16.0) ...\n",
      "Processing triggers for libc-bin (2.39-0ubuntu8.3) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install libedgetpu1-std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load Edge TPU delegate: Failed to load delegate from libedgetpu.so.1\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Encountered unresolved custom op: edgetpu-custom-op.\nSee instructions: https://www.tensorflow.org/lite/guide/ops_custom Node number 0 (edgetpu-custom-op) failed to prepare.Encountered unresolved custom op: edgetpu-custom-op.\nSee instructions: https://www.tensorflow.org/lite/guide/ops_custom Node number 0 (edgetpu-custom-op) failed to prepare.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Fall back to the default interpreter if needed.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter(model_path\u001b[38;5;241m=\u001b[39mMODEL_PATH)\n\u001b[0;32m---> 19\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get input and output details from the model\u001b[39;00m\n\u001b[1;32m     22\u001b[0m input_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()\n",
      "File \u001b[0;32m~/miniconda/envs/FTCTrainingEnv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:531\u001b[0m, in \u001b[0;36mInterpreter.allocate_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mallocate_tensors\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_safe()\n\u001b[0;32m--> 531\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAllocateTensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Encountered unresolved custom op: edgetpu-custom-op.\nSee instructions: https://www.tensorflow.org/lite/guide/ops_custom Node number 0 (edgetpu-custom-op) failed to prepare.Encountered unresolved custom op: edgetpu-custom-op.\nSee instructions: https://www.tensorflow.org/lite/guide/ops_custom Node number 0 (edgetpu-custom-op) failed to prepare."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to your quantized 8-bit model compiled for the Edge TPU\n",
    "MODEL_PATH = '/root/MultiAgent/FTCTraining/final_output/limelight_neural_detector_coral.tflite'\n",
    "\n",
    "# Try to load the Edge TPU delegate\n",
    "try:\n",
    "    edgetpu_delegate = tf.lite.experimental.load_delegate('libedgetpu.so.1')\n",
    "    interpreter = tf.lite.Interpreter(model_path=MODEL_PATH,\n",
    "                                        experimental_delegates=[edgetpu_delegate])\n",
    "    print(\"Edge TPU delegate loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load Edge TPU delegate:\", e)\n",
    "    # Fall back to the default interpreter if needed.\n",
    "    interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details from the model\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get input dimensions (assuming input tensor shape is [1, height, width, channels])\n",
    "input_shape = input_details[0]['shape']\n",
    "model_height = input_shape[1]\n",
    "model_width = input_shape[2]\n",
    "\n",
    "# Define a minimum detection threshold (adjust as needed)\n",
    "DETECTION_THRESHOLD = 0.5\n",
    "\n",
    "# Open the default camera (change 0 to another index if necessary)\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Starting video stream... Press 'q' to exit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame: resize to model dimensions and convert to uint8 (for quantized models)\n",
    "    resized_frame = cv2.resize(frame, (model_width, model_height))\n",
    "    input_data = np.expand_dims(resized_frame, axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Retrieve detection results.\n",
    "    # (Assumes the model output structure is similar to the TF2 Object Detection API)\n",
    "    boxes = interpreter.get_tensor(output_details[0]['index'])[0]       # shape: [num_detections, 4]\n",
    "    classes = interpreter.get_tensor(output_details[1]['index'])[0]     # shape: [num_detections]\n",
    "    scores = interpreter.get_tensor(output_details[2]['index'])[0]      # shape: [num_detections]\n",
    "    num_detections = int(interpreter.get_tensor(output_details[3]['index'])[0])\n",
    "    \n",
    "    # Draw detections on the original frame\n",
    "    imH, imW, _ = frame.shape\n",
    "    for i in range(num_detections):\n",
    "        if scores[i] >= DETECTION_THRESHOLD:\n",
    "            # Convert normalized box coordinates to pixel values.\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            xmin = int(xmin * imW)\n",
    "            xmax = int(xmax * imW)\n",
    "            ymin = int(ymin * imH)\n",
    "            ymax = int(ymax * imH)\n",
    "\n",
    "            # Draw the bounding box and label\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n",
    "            label = f'ID:{int(classes[i])} {scores[i]:.2f}'\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (10, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detections\n",
    "    cv2.imshow('8-bit Quantized Edge TPU Model Inference', frame)\n",
    "    \n",
    "    # Exit the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FTCTrainingEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
